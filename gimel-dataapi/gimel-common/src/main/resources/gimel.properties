# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
# 
#   http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

# HBASE Schema
gimel.hbase.namespace.name=gimel
# Confluent Schema
gimel.zookeeper.host=zk_host:2181
gimel.kafka.confluent.schema.url=http://confluent_schema_registry:8081
# Kafka
gimel.kafka.broker=kafka_broker:9092
gimel.kafka.consumer.checkpoint.root=/pcatalog/kafka_consumer/checkpoint
gimel.kafka.cdh.coreSchema=
# Elastic Search
es.nodes=http://elastic_host
es.port=8080
# Kerberos
gimel.keytab=USER.keytab
gimel.principal=USER
# Zookeeper node path for maintaining state
gimel.zk.state.prefix=/pcatalog/discovery/schema-update/checkpoint
gimel.cluster=hadoop_cluster_name
spark.jdbc.p.file=/tmp/password/teradata/pass.dat
# SmokeTest
smoketest.kafka.cdh.hive.table=pc_smoketest_kafka
smoketest.kafka.cdh.topic=flights.flights_log
smoketest.kafka.hive.table=pc_smoketest_kafka_only
smoketest.kafka.topic=pc_smoke_test_topic
smoketest.es.hive.table=pc_smoketest_es
smoketest.es.index=pc_smoke_test_index
smoketest.hive.table=pc_smoketest_hive
smoketest.hbase.hive.table=pc_smoketest_hbase
smoketest.hbase.table=pc_smoketest_hbase
smoketest.hbase.table.row.key=id
smoketest.hbase.table.columnfamily=personal,professional
smoketest.hbase.table.columns=rowKey:id|personal:name,age,address|professional:company,designation,salary
smoketest.hbase.namespace=adp_bdpe
smoketest.hbase.site.xml.hdfs=hdfs:///tmp/hbase-site.xml
smoketest.hbase.site.xml.local=/tmp/hbase-site.xml
smoketest.gimel.sample.rows.count=1000
smoketest.result.stats.es.host=http://elastic_host
smoketest.result.stats.es.port=8080
smoketest.result.stats.es.index=pcatalog_smoketest_result
#kafka Stream
smoketest.kafka.stream.hive.table=pc_smoketest_kafka_streaming
smoketest.kafka.stream.es.hive.table=pc_smoketest_kafka_streaming_es
smoketest.kafka.stream.es.index=pc_smoketest_kafka_streaming_es_index
smoketest.kafka.stream.batch.interval=30
smoketest.gimel.streaming.awaitTerminationOrTimeout=60000
# HiveDB and Location
smoketest.gimel.hive.db=pcatalog_smoke_test
smoketest.gimel.hive.location=/tmp/pcatalog
#Teradata
smoketest.teradata.table=pc_smoketest_teradata
smoketest.teradata.db=scratch_db
smoketest.gimel.hive.table=pc_smoktest_teradata_hive
smoketest.teradata.username=user
smoketest.teradata.p.file=hdfs:///tmp/password/teradata/pass.dat
smoketest.teradata.url=teradata_server
smoketest.teradata.write.type=FASTLOAD
smoketest.teradata.read.type=FASTEXPORT
smoketest.teradata.sessions=8
smoketest.teradata.batchsize=10000
# Aerospike
smoketest.aerospike.hive.table=pc_smoketest_aerospike_hive
smoketest.aerospike.set.name=pc_smoketest_aerospike
smoketest.aerospike.namespace.name=test
smoketest.aerospike.client=aerospike_host
smoketest.aerospike.port=3000
smoketest.aerospike.rowkey=id

# Monitoring SCAAS
gimel.query.monitor.stats.es.dataset=pcatalog.pcatalog_query_monitor_es
gimel.query.monitor.stats.es.index=pcatalog_pcatalog_query_monitor
gimel.query.monitor.stats.es.host=http://elastic_host
gimel.query.monitor.stats.es.port=8080
gimel.query.monitor.stats.kafka.dataset=pcatalog.pcatalog_query_monitor_kafka
gimel.query.monitor.stats.kafka.topic=pcatalog_pcatalog_query_monitor
gimel.query.monitor.stats.kafka.broker=kafka_broker:9092
gimel.query.monitor.stats.zookeeper.host=zk_host:2181

# DataSet Deployment Clusters
gimel.dataset.deployment.clusters=hadoop_cluster_1,hadoop_cluster_2

# HBase hbase-site.xml hdfs paths
gimel.hiveJars.ddl=hdfs:///tmp/hive-hbase-handler-1.2.1000.2.4.2.12-1.jar,hdfs:///tmp/elasticsearch-hadoop-2.3.3.jar
gimel.hbase.site.xml.path=/etc/hbase/conf/hbase-site.xml

# ES Cluster
gimel.es.elasticadpcluster.url=http://elastic_host8080
gimel.es.polling=elasticadpcluster

# Poller
gimel.polling.logger.kafka.topic=data_catalog_pollingmetrics
